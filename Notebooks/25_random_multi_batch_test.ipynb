{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from random import shuffle\n",
    "from wearsed.dataset.WearSEDDataset import WearSEDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WearSEDDataset(mesaid_path='../wearsed/dataset/data_ids/', signals_to_read=['SpO2', 'Pleth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_start(labels, max_time, seq_length):\n",
    "    start = torch.randint(0, max_time, (1,)).item()\n",
    "    end = start + seq_length\n",
    "    return start, labels[start:end].sum() > 0\n",
    "\n",
    "def get_batch(signals, labels, batch_size, seq_length):\n",
    "    (hypnogram, spo2, pleth) = signals\n",
    "    max_time = len(labels) - seq_length\n",
    "\n",
    "    tries = 0\n",
    "    random_starts = []\n",
    "    while len(random_starts) < batch_size:\n",
    "        random_start, has_positive_class = get_random_start(labels, max_time, seq_length)\n",
    "        if has_positive_class or tries >= batch_size // 2:\n",
    "            random_starts.append(random_start)\n",
    "        tries += 1\n",
    "    shuffle(random_starts)\n",
    "\n",
    "    batch_signals = []\n",
    "    batch_labels = []\n",
    "    for start in random_starts:\n",
    "        end = start + seq_length\n",
    "        seq_hypnogram = hypnogram[start:end].view((1, -1))\n",
    "        seq_spo2 = spo2[start:end].view((1, -1))\n",
    "        seq_pleth = pleth[start*256:end*256].view((256, -1))\n",
    "        combined_signal = torch.cat([seq_hypnogram, seq_spo2, seq_pleth], dim=0)\n",
    "        batch_signals.append(combined_signal)\n",
    "        batch_labels.append(labels[start:end])\n",
    "\n",
    "    return torch.stack(batch_signals), torch.stack(batch_labels)\n",
    "\n",
    "def get_multi_batch(dataset, i, multi_batch_size, batch_size, seq_length):\n",
    "    multi_batch_signals = []\n",
    "    multi_batch_labels  = []\n",
    "    for j in range(multi_batch_size):\n",
    "        (hypnogram, spo2, pleth), event_or_not = dataset[multi_batch_size*i+j]\n",
    "        batch_signal, batch_label = get_batch((hypnogram, spo2, pleth), event_or_not, batch_size, seq_length)\n",
    "        multi_batch_signals.append(batch_signal)\n",
    "        multi_batch_labels.append(batch_label)\n",
    "    return torch.cat(multi_batch_signals), torch.cat(multi_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mb_sig.shape=torch.Size([128, 258, 1800])\n",
      "mb_lbl.shape=torch.Size([128, 1800])\n"
     ]
    }
   ],
   "source": [
    "mb_sig, mb_lbl = get_multi_batch(dataset, 0, 4, 32, 30*60)\n",
    "\n",
    "print(f'{mb_sig.shape=}')\n",
    "print(f'{mb_lbl.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
